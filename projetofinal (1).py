# -*- coding: utf-8 -*-
"""ProjetoFinal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IRIi7UYaMRw9v3ByIYzIDMUlC64UgBMm
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

df = pd.read_csv('/content/Diabetes_prediction.csv')

cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction']
for col in cols:
    df[col] = round(df[col], 2)
df['Age'] = df['Age'].astype('int64')

plt.figure(figsize=(10, 8))
sns.pairplot(df)
plt.suptitle('Pairplot das características', y=1.02)
plt.show()

plt.figure(figsize=(10, 8))
df.plot(kind='kde', layout=(3, 3), subplots=True, figsize=(10, 8))
plt.tight_layout()
plt.show()

cols = ['Glucose','BloodPressure','SkinThickness','Insulin','DiabetesPedigreeFunction','Age']

for i in cols:
    plt.figure(figsize=(8, 6))
    sns.scatterplot(x=df[i], y=df['BMI'], hue='Diagnosis', data=df)
    plt.title(f'Gráfico de Dispersão de {i} e IMC')
    plt.ylabel('IMC')
    plt.xlabel(f'{i}')
    plt.legend(title='Diagnóstico', loc='upper right')
    plt.show()

# Dividindo os dados em conjunto de treinamento e teste
X = df.drop('Diagnosis', axis=1)
y = df['Diagnosis']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Padronização das características
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Modelagem com SVM
svm_model = SVC(kernel='linear')
svm_model.fit(X_train_scaled, y_train)
svm_pred = svm_model.predict(X_test_scaled)

# Avaliação do modelo SVM
svm_accuracy = accuracy_score(y_test, svm_pred)
svm_precision = precision_score(y_test, svm_pred)
svm_recall = recall_score(y_test, svm_pred)
svm_f1 = f1_score(y_test, svm_pred)
print("Support Vector Machine (SVM):")
print(f"Accuracy: {svm_accuracy:.2f}")
print(f"Precision: {svm_precision:.2f}")
print(f"Recall: {svm_recall:.2f}")
print(f"F1 Score: {svm_f1:.2f}")
print()

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Modelagem com Gradient Boosting
gb_model = GradientBoostingClassifier()
gb_model.fit(X_train_scaled, y_train)
gb_pred = gb_model.predict(X_test_scaled)

# Avaliação do modelo Gradient Boosting
gb_accuracy = accuracy_score(y_test, gb_pred)
gb_precision = precision_score(y_test, gb_pred)
gb_recall = recall_score(y_test, gb_pred)
gb_f1 = f1_score(y_test, gb_pred)
print("Gradient Boosting:")
print(f"Accuracy: {gb_accuracy:.2f}")
print(f"Precision: {gb_precision:.2f}")
print(f"Recall: {gb_recall:.2f}")
print(f"F1 Score: {gb_f1:.2f}")
print()

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Validando os modelos com Cross-Validation
svm_cv_scores = cross_val_score(svm_model, X_train_scaled, y_train, cv=5)
gb_cv_scores = cross_val_score(gb_model, X_train_scaled, y_train, cv=5)

print("Cross-Validation Scores:")
print(f"SVM: {svm_cv_scores.mean():.2f} (+/- {svm_cv_scores.std() * 2:.2f})")
print(f"Gradient Boosting: {gb_cv_scores.mean():.2f} (+/- {gb_cv_scores.std() * 2:.2f})")

## A conclusão deste código é que o modelo de Support Vector Machine (SVM) obteve um desempenho ligeiramente melhor do que o modelo de Gradient Boosting (Regressão Linear) na tarefa de previsão de diabetes, com base nas métricas de precisão, recall e F1-score. No entanto, essas diferenças podem ser pequenas e podem variar dependendo do conjunto de dados específico e das escolhas de hiperparâmetros.
## Além disso, ao validar os modelos com cross-validation, observamos que ambos os modelos têm desempenhos consistentes, com pontuações médias próximas. Isso sugere que ambos os modelos são capazes de generalizar bem para dados não vistos.
## Em resumo, tanto o SVM quanto o Gradient Boosting são modelos viáveis para previsão de diabetes com base nos dados fornecidos. A escolha entre os dois pode depender de considerações adicionais, como interpretabilidade do modelo, complexidade computacional ou preferências pessoais.

## Este código está voltado para um problema de classificação, mais especificamente para prever se um indivíduo tem diabetes ou não, com base em várias características relacionadas aos fatores de risco do diabetes.
## Os modelos utilizados, Support Vector Machine (SVM) e Gradient Boosting, são comumente aplicados em problemas de classificação, onde o objetivo é prever uma categoria ou classe específica para cada instância de dados.
## Portanto, as métricas de avaliação utilizadas, como precisão, recall e F1-score, são indicadores do desempenho do modelo na tarefa de classificação.

# Importando as bibliotecas necessárias
from sklearn.tree import DecisionTreeClassifier

# Modelagem com Árvore de Decisão (CART)
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train_scaled, y_train)
dt_pred = dt_model.predict(X_test_scaled)

# Avaliação do modelo Árvore de Decisão
dt_accuracy = accuracy_score(y_test, dt_pred)
dt_precision = precision_score(y_test, dt_pred)
dt_recall = recall_score(y_test, dt_pred)
dt_f1 = f1_score(y_test, dt_pred)
print("Decision Tree (CART):")
print(f"Accuracy: {dt_accuracy:.2f}")
print(f"Precision: {dt_precision:.2f}")
print(f"Recall: {dt_recall:.2f}")
print(f"F1 Score: {dt_f1:.2f}")
print()

from sklearn.tree import DecisionTreeClassifier

# Validando o modelo com Cross-Validation
dt_cv_scores = cross_val_score(dt_model, X_train_scaled, y_train, cv=5)

print("Cross-Validation Scores:")
print(f"Decision Tree (CART): {dt_cv_scores.mean():.2f} (+/- {dt_cv_scores.std() * 2:.2f})")

## a escolha entre os três modelos pode depender de considerações adicionais, como interpretabilidade do modelo, complexidade computacional, preferências pessoais ou requisitos específicos do problema.

## Com base nos resultados dos modelos de Support Vector Machine (SVM), Gradient Boosting e Árvore de Decisão (CART) obtidos nos códigos acima, é difícil determinar objetivamente qual é o "melhor" modelo. A escolha do modelo mais adequado pode depender de vários fatores, incluindo:

## Desempenho em Métricas de Avaliação: É importante considerar métricas como precisão, recall e F1-score para avaliar o desempenho de cada modelo. O modelo com as métricas mais altas pode ser considerado o melhor em termos de precisão e capacidade de identificar corretamente os casos positivos.

## Interpretabilidade: Modelos como Árvores de Decisão são mais fáceis de interpretar e explicar, enquanto modelos como SVM podem ser mais difíceis de entender devido à sua natureza mais complexa.

## Complexidade do Modelo: Modelos mais complexos, como Gradient Boosting, podem ter um desempenho melhor em conjuntos de dados grandes e complexos, mas também podem ser mais suscetíveis a overfitting.

## Requisitos Computacionais: Alguns modelos, como SVM, podem exigir mais recursos computacionais durante o treinamento e a previsão, o que pode ser uma consideração importante dependendo das restrições do sistema.

## Dito isso, minha opinião é que o modelo de Gradient Boosting pode ser uma escolha sólida com base nos resultados. Ele geralmente tem um desempenho muito bom em uma variedade de conjuntos de dados e é menos propenso a overfitting do que outros modelos complexos, como redes neurais profundas. Além disso, é mais fácil de interpretar do que um SVM e geralmente requer menos ajuste de hiperparâmetros.